{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-24YCI0X6P3J"
   },
   "source": [
    "# Initial installs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "collapsed": true,
    "id": "qu4VLGfduYS7",
    "outputId": "925a1d02-7b58-4bf7-a359-e570b9b67be6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Collecting google-generativeai\n",
      "  Downloading google_generativeai-0.8.3-py3-none-any.whl.metadata (3.9 kB)\n",
      "Collecting google-ai-generativelanguage==0.6.10 (from google-generativeai)\n",
      "  Downloading google_ai_generativelanguage-0.6.10-py3-none-any.whl.metadata (5.6 kB)\n",
      "Collecting google-api-core (from google-generativeai)\n",
      "  Downloading google_api_core-2.23.0-py3-none-any.whl.metadata (3.0 kB)\n",
      "Collecting google-api-python-client (from google-generativeai)\n",
      "  Downloading google_api_python_client-2.153.0-py2.py3-none-any.whl.metadata (6.7 kB)\n",
      "Collecting google-auth>=2.15.0 (from google-generativeai)\n",
      "  Downloading google_auth-2.36.0-py2.py3-none-any.whl.metadata (4.7 kB)\n",
      "Requirement already satisfied: protobuf in c:\\programdata\\anaconda3\\lib\\site-packages (from google-generativeai) (3.20.3)\n",
      "Requirement already satisfied: pydantic in c:\\programdata\\anaconda3\\lib\\site-packages (from google-generativeai) (1.10.12)\n",
      "Requirement already satisfied: tqdm in c:\\programdata\\anaconda3\\lib\\site-packages (from google-generativeai) (4.65.0)\n",
      "Requirement already satisfied: typing-extensions in c:\\programdata\\anaconda3\\lib\\site-packages (from google-generativeai) (4.9.0)\n",
      "Collecting proto-plus<2.0.0dev,>=1.22.3 (from google-ai-generativelanguage==0.6.10->google-generativeai)\n",
      "  Downloading proto_plus-1.25.0-py3-none-any.whl.metadata (2.2 kB)\n",
      "Collecting googleapis-common-protos<2.0.dev0,>=1.56.2 (from google-api-core->google-generativeai)\n",
      "  Downloading googleapis_common_protos-1.66.0-py2.py3-none-any.whl.metadata (1.5 kB)\n",
      "Requirement already satisfied: requests<3.0.0.dev0,>=2.18.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from google-api-core->google-generativeai) (2.31.0)\n",
      "Requirement already satisfied: cachetools<6.0,>=2.0.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from google-auth>=2.15.0->google-generativeai) (4.2.2)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from google-auth>=2.15.0->google-generativeai) (0.2.8)\n",
      "Collecting rsa<5,>=3.1.4 (from google-auth>=2.15.0->google-generativeai)\n",
      "  Downloading rsa-4.9-py3-none-any.whl.metadata (4.2 kB)\n",
      "Collecting httplib2<1.dev0,>=0.19.0 (from google-api-python-client->google-generativeai)\n",
      "  Downloading httplib2-0.22.0-py3-none-any.whl.metadata (2.6 kB)\n",
      "Collecting google-auth-httplib2<1.0.0,>=0.2.0 (from google-api-python-client->google-generativeai)\n",
      "  Downloading google_auth_httplib2-0.2.0-py2.py3-none-any.whl.metadata (2.2 kB)\n",
      "Collecting uritemplate<5,>=3.0.1 (from google-api-python-client->google-generativeai)\n",
      "  Downloading uritemplate-4.1.1-py2.py3-none-any.whl.metadata (2.9 kB)\n",
      "Requirement already satisfied: colorama in c:\\programdata\\anaconda3\\lib\\site-packages (from tqdm->google-generativeai) (0.4.6)\n",
      "Collecting grpcio<2.0dev,>=1.33.2 (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.1->google-ai-generativelanguage==0.6.10->google-generativeai)\n",
      "  Downloading grpcio-1.68.0-cp311-cp311-win_amd64.whl.metadata (4.0 kB)\n",
      "Collecting grpcio-status<2.0.dev0,>=1.33.2 (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.1->google-ai-generativelanguage==0.6.10->google-generativeai)\n",
      "  Downloading grpcio_status-1.68.0-py3-none-any.whl.metadata (1.1 kB)\n",
      "Requirement already satisfied: pyparsing!=3.0.0,!=3.0.1,!=3.0.2,!=3.0.3,<4,>=2.4.2 in c:\\programdata\\anaconda3\\lib\\site-packages (from httplib2<1.dev0,>=0.19.0->google-api-python-client->google-generativeai) (3.0.9)\n",
      "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in c:\\programdata\\anaconda3\\lib\\site-packages (from pyasn1-modules>=0.2.1->google-auth>=2.15.0->google-generativeai) (0.4.8)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\programdata\\anaconda3\\lib\\site-packages (from requests<3.0.0.dev0,>=2.18.0->google-api-core->google-generativeai) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\programdata\\anaconda3\\lib\\site-packages (from requests<3.0.0.dev0,>=2.18.0->google-api-core->google-generativeai) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from requests<3.0.0.dev0,>=2.18.0->google-api-core->google-generativeai) (2.0.7)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\programdata\\anaconda3\\lib\\site-packages (from requests<3.0.0.dev0,>=2.18.0->google-api-core->google-generativeai) (2024.2.2)\n",
      "Collecting protobuf (from google-generativeai)\n",
      "  Downloading protobuf-5.28.3-cp310-abi3-win_amd64.whl.metadata (592 bytes)\n",
      "Downloading google_generativeai-0.8.3-py3-none-any.whl (160 kB)\n",
      "   ---------------------------------------- 0.0/160.8 kB ? eta -:--:--\n",
      "   ------- -------------------------------- 30.7/160.8 kB 1.3 MB/s eta 0:00:01\n",
      "   ---------------------- ----------------- 92.2/160.8 kB 1.0 MB/s eta 0:00:01\n",
      "   -------------------------------------- - 153.6/160.8 kB 1.1 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 160.8/160.8 kB 1.2 MB/s eta 0:00:00\n",
      "Downloading google_ai_generativelanguage-0.6.10-py3-none-any.whl (760 kB)\n",
      "   ---------------------------------------- 0.0/760.0 kB ? eta -:--:--\n",
      "   --------- ------------------------------ 184.3/760.0 kB 5.4 MB/s eta 0:00:01\n",
      "   ---------------------- ----------------- 419.8/760.0 kB 5.3 MB/s eta 0:00:01\n",
      "   -------------------------------------- - 727.0/760.0 kB 5.7 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 760.0/760.0 kB 5.3 MB/s eta 0:00:00\n",
      "Downloading google_api_core-2.23.0-py3-none-any.whl (156 kB)\n",
      "   ---------------------------------------- 0.0/156.6 kB ? eta -:--:--\n",
      "   ------------------ --------------------- 71.7/156.6 kB 3.8 MB/s eta 0:00:01\n",
      "   ------------------------------- -------- 122.9/156.6 kB 1.4 MB/s eta 0:00:01\n",
      "   ------------------------------- -------- 122.9/156.6 kB 1.4 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 156.6/156.6 kB 1.2 MB/s eta 0:00:00\n",
      "Downloading google_auth-2.36.0-py2.py3-none-any.whl (209 kB)\n",
      "   ---------------------------------------- 0.0/209.5 kB ? eta -:--:--\n",
      "   ---------------------------------------- 209.5/209.5 kB 6.2 MB/s eta 0:00:00\n",
      "Downloading google_api_python_client-2.153.0-py2.py3-none-any.whl (12.6 MB)\n",
      "   ---------------------------------------- 0.0/12.6 MB ? eta -:--:--\n",
      "   - -------------------------------------- 0.4/12.6 MB 13.9 MB/s eta 0:00:01\n",
      "   -- ------------------------------------- 0.9/12.6 MB 14.5 MB/s eta 0:00:01\n",
      "   ---- ----------------------------------- 1.4/12.6 MB 13.1 MB/s eta 0:00:01\n",
      "   ----- ---------------------------------- 1.9/12.6 MB 13.1 MB/s eta 0:00:01\n",
      "   ------- -------------------------------- 2.3/12.6 MB 12.1 MB/s eta 0:00:01\n",
      "   -------- ------------------------------- 2.8/12.6 MB 12.6 MB/s eta 0:00:01\n",
      "   ---------- ----------------------------- 3.2/12.6 MB 12.7 MB/s eta 0:00:01\n",
      "   ----------- ---------------------------- 3.6/12.6 MB 12.1 MB/s eta 0:00:01\n",
      "   ------------- -------------------------- 4.1/12.6 MB 11.9 MB/s eta 0:00:01\n",
      "   -------------- ------------------------- 4.6/12.6 MB 12.3 MB/s eta 0:00:01\n",
      "   --------------- ------------------------ 5.0/12.6 MB 12.3 MB/s eta 0:00:01\n",
      "   ----------------- ---------------------- 5.5/12.6 MB 12.2 MB/s eta 0:00:01\n",
      "   ------------------ --------------------- 6.0/12.6 MB 12.3 MB/s eta 0:00:01\n",
      "   -------------------- ------------------- 6.5/12.6 MB 12.1 MB/s eta 0:00:01\n",
      "   ---------------------- ----------------- 7.0/12.6 MB 12.0 MB/s eta 0:00:01\n",
      "   ----------------------- ---------------- 7.4/12.6 MB 12.1 MB/s eta 0:00:01\n",
      "   ------------------------- -------------- 7.9/12.6 MB 12.0 MB/s eta 0:00:01\n",
      "   -------------------------- ------------- 8.4/12.6 MB 12.1 MB/s eta 0:00:01\n",
      "   ---------------------------- ----------- 8.8/12.6 MB 12.0 MB/s eta 0:00:01\n",
      "   ----------------------------- ---------- 9.2/12.6 MB 12.0 MB/s eta 0:00:01\n",
      "   ------------------------------ --------- 9.7/12.6 MB 12.2 MB/s eta 0:00:01\n",
      "   -------------------------------- ------- 10.1/12.6 MB 12.0 MB/s eta 0:00:01\n",
      "   --------------------------------- ------ 10.5/12.6 MB 11.9 MB/s eta 0:00:01\n",
      "   ----------------------------------- ---- 11.0/12.6 MB 12.1 MB/s eta 0:00:01\n",
      "   ------------------------------------ --- 11.5/12.6 MB 11.9 MB/s eta 0:00:01\n",
      "   -------------------------------------- - 12.0/12.6 MB 12.1 MB/s eta 0:00:01\n",
      "   ---------------------------------------  12.4/12.6 MB 11.9 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 12.6/12.6 MB 11.9 MB/s eta 0:00:00\n",
      "Downloading google_auth_httplib2-0.2.0-py2.py3-none-any.whl (9.3 kB)\n",
      "Downloading googleapis_common_protos-1.66.0-py2.py3-none-any.whl (221 kB)\n",
      "   ---------------------------------------- 0.0/221.7 kB ? eta -:--:--\n",
      "   --------------------------------------- 221.7/221.7 kB 13.2 MB/s eta 0:00:00\n",
      "Downloading httplib2-0.22.0-py3-none-any.whl (96 kB)\n",
      "   ---------------------------------------- 0.0/96.9 kB ? eta -:--:--\n",
      "   ---------------------------------------- 96.9/96.9 kB 5.4 MB/s eta 0:00:00\n",
      "Downloading proto_plus-1.25.0-py3-none-any.whl (50 kB)\n",
      "   ---------------------------------------- 0.0/50.1 kB ? eta -:--:--\n",
      "   ---------------------------------------- 50.1/50.1 kB ? eta 0:00:00\n",
      "Downloading rsa-4.9-py3-none-any.whl (34 kB)\n",
      "Downloading uritemplate-4.1.1-py2.py3-none-any.whl (10 kB)\n",
      "Downloading grpcio-1.68.0-cp311-cp311-win_amd64.whl (4.4 MB)\n",
      "   ---------------------------------------- 0.0/4.4 MB ? eta -:--:--\n",
      "   --- ------------------------------------ 0.4/4.4 MB 13.2 MB/s eta 0:00:01\n",
      "   ------- -------------------------------- 0.9/4.4 MB 10.9 MB/s eta 0:00:01\n",
      "   ----------- ---------------------------- 1.3/4.4 MB 11.6 MB/s eta 0:00:01\n",
      "   ---------------- ----------------------- 1.8/4.4 MB 12.6 MB/s eta 0:00:01\n",
      "   -------------------- ------------------- 2.2/4.4 MB 11.7 MB/s eta 0:00:01\n",
      "   ----------------------- ---------------- 2.6/4.4 MB 12.8 MB/s eta 0:00:01\n",
      "   --------------------------- ------------ 3.0/4.4 MB 12.1 MB/s eta 0:00:01\n",
      "   -------------------------------- ------- 3.5/4.4 MB 11.9 MB/s eta 0:00:01\n",
      "   ----------------------------------- ---- 4.0/4.4 MB 12.0 MB/s eta 0:00:01\n",
      "   ---------------------------------------  4.4/4.4 MB 12.1 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 4.4/4.4 MB 11.7 MB/s eta 0:00:00\n",
      "Downloading grpcio_status-1.68.0-py3-none-any.whl (14 kB)\n",
      "Downloading protobuf-5.28.3-cp310-abi3-win_amd64.whl (431 kB)\n",
      "   ---------------------------------------- 0.0/431.5 kB ? eta -:--:--\n",
      "   ------------------------------------ -- 399.4/431.5 kB 12.6 MB/s eta 0:00:01\n",
      "   --------------------------------------- 431.5/431.5 kB 13.6 MB/s eta 0:00:00\n",
      "Installing collected packages: uritemplate, rsa, protobuf, httplib2, grpcio, proto-plus, googleapis-common-protos, google-auth, grpcio-status, google-auth-httplib2, google-api-core, google-api-python-client, google-ai-generativelanguage, google-generativeai\n",
      "Successfully installed google-ai-generativelanguage-0.6.10 google-api-core-2.23.0 google-api-python-client-2.153.0 google-auth-2.36.0 google-auth-httplib2-0.2.0 google-generativeai-0.8.3 googleapis-common-protos-1.66.0 grpcio-1.68.0 grpcio-status-1.68.0 httplib2-0.22.0 proto-plus-1.25.0 protobuf-5.28.3 rsa-4.9 uritemplate-4.1.1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "streamlit 1.30.0 requires protobuf<5,>=3.20, but you have protobuf 5.28.3 which is incompatible.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Collecting pymongo\n",
      "  Downloading pymongo-4.10.1-cp311-cp311-win_amd64.whl.metadata (22 kB)\n",
      "Collecting sentence-transformers\n",
      "  Using cached sentence_transformers-3.3.0-py3-none-any.whl.metadata (10 kB)\n",
      "Collecting dnspython<3.0.0,>=1.16.0 (from pymongo)\n",
      "  Using cached dnspython-2.7.0-py3-none-any.whl.metadata (5.8 kB)\n",
      "Collecting transformers<5.0.0,>=4.41.0 (from sentence-transformers)\n",
      "  Using cached transformers-4.46.2-py3-none-any.whl.metadata (44 kB)\n",
      "Requirement already satisfied: tqdm in c:\\programdata\\anaconda3\\lib\\site-packages (from sentence-transformers) (4.65.0)\n",
      "Requirement already satisfied: torch>=1.11.0 in c:\\users\\ziziz\\appdata\\roaming\\python\\python311\\site-packages (from sentence-transformers) (2.3.1)\n",
      "Requirement already satisfied: scikit-learn in c:\\programdata\\anaconda3\\lib\\site-packages (from sentence-transformers) (1.2.2)\n",
      "Requirement already satisfied: scipy in c:\\programdata\\anaconda3\\lib\\site-packages (from sentence-transformers) (1.11.4)\n",
      "Collecting huggingface-hub>=0.20.0 (from sentence-transformers)\n",
      "  Using cached huggingface_hub-0.26.2-py3-none-any.whl.metadata (13 kB)\n",
      "Requirement already satisfied: Pillow in c:\\programdata\\anaconda3\\lib\\site-packages (from sentence-transformers) (10.2.0)\n",
      "Requirement already satisfied: filelock in c:\\programdata\\anaconda3\\lib\\site-packages (from huggingface-hub>=0.20.0->sentence-transformers) (3.13.1)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from huggingface-hub>=0.20.0->sentence-transformers) (2023.10.0)\n",
      "Requirement already satisfied: packaging>=20.9 in c:\\users\\ziziz\\appdata\\roaming\\python\\python311\\site-packages (from huggingface-hub>=0.20.0->sentence-transformers) (23.2)\n",
      "Requirement already satisfied: pyyaml>=5.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from huggingface-hub>=0.20.0->sentence-transformers) (6.0.1)\n",
      "Requirement already satisfied: requests in c:\\programdata\\anaconda3\\lib\\site-packages (from huggingface-hub>=0.20.0->sentence-transformers) (2.31.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in c:\\programdata\\anaconda3\\lib\\site-packages (from huggingface-hub>=0.20.0->sentence-transformers) (4.9.0)\n",
      "Requirement already satisfied: sympy in c:\\programdata\\anaconda3\\lib\\site-packages (from torch>=1.11.0->sentence-transformers) (1.12)\n",
      "Requirement already satisfied: networkx in c:\\programdata\\anaconda3\\lib\\site-packages (from torch>=1.11.0->sentence-transformers) (3.1)\n",
      "Requirement already satisfied: jinja2 in c:\\programdata\\anaconda3\\lib\\site-packages (from torch>=1.11.0->sentence-transformers) (3.1.3)\n",
      "Requirement already satisfied: mkl<=2021.4.0,>=2021.1.1 in c:\\users\\ziziz\\appdata\\roaming\\python\\python311\\site-packages (from torch>=1.11.0->sentence-transformers) (2021.4.0)\n",
      "Requirement already satisfied: colorama in c:\\programdata\\anaconda3\\lib\\site-packages (from tqdm->sentence-transformers) (0.4.6)\n",
      "Requirement already satisfied: numpy>=1.17 in c:\\programdata\\anaconda3\\lib\\site-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (1.26.4)\n",
      "Requirement already satisfied: regex!=2019.12.17 in c:\\programdata\\anaconda3\\lib\\site-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (2023.10.3)\n",
      "Collecting safetensors>=0.4.1 (from transformers<5.0.0,>=4.41.0->sentence-transformers)\n",
      "  Downloading safetensors-0.4.5-cp311-none-win_amd64.whl.metadata (3.9 kB)\n",
      "Collecting tokenizers<0.21,>=0.20 (from transformers<5.0.0,>=4.41.0->sentence-transformers)\n",
      "  Downloading tokenizers-0.20.3-cp311-none-win_amd64.whl.metadata (6.9 kB)\n",
      "Requirement already satisfied: joblib>=1.1.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from scikit-learn->sentence-transformers) (1.2.0)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from scikit-learn->sentence-transformers) (2.2.0)\n",
      "Requirement already satisfied: intel-openmp==2021.* in c:\\users\\ziziz\\appdata\\roaming\\python\\python311\\site-packages (from mkl<=2021.4.0,>=2021.1.1->torch>=1.11.0->sentence-transformers) (2021.4.0)\n",
      "Requirement already satisfied: tbb==2021.* in c:\\users\\ziziz\\appdata\\roaming\\python\\python311\\site-packages (from mkl<=2021.4.0,>=2021.1.1->torch>=1.11.0->sentence-transformers) (2021.12.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from jinja2->torch>=1.11.0->sentence-transformers) (2.1.3)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\programdata\\anaconda3\\lib\\site-packages (from requests->huggingface-hub>=0.20.0->sentence-transformers) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\programdata\\anaconda3\\lib\\site-packages (from requests->huggingface-hub>=0.20.0->sentence-transformers) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from requests->huggingface-hub>=0.20.0->sentence-transformers) (2.0.7)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\programdata\\anaconda3\\lib\\site-packages (from requests->huggingface-hub>=0.20.0->sentence-transformers) (2024.2.2)\n",
      "Requirement already satisfied: mpmath>=0.19 in c:\\programdata\\anaconda3\\lib\\site-packages (from sympy->torch>=1.11.0->sentence-transformers) (1.3.0)\n",
      "Downloading pymongo-4.10.1-cp311-cp311-win_amd64.whl (876 kB)\n",
      "   ---------------------------------------- 0.0/876.5 kB ? eta -:--:--\n",
      "   - -------------------------------------- 30.7/876.5 kB 1.3 MB/s eta 0:00:01\n",
      "   ---- ----------------------------------- 102.4/876.5 kB 1.5 MB/s eta 0:00:01\n",
      "   -------------- ------------------------- 307.2/876.5 kB 2.7 MB/s eta 0:00:01\n",
      "   ------------------------------ --------- 665.6/876.5 kB 4.6 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 876.5/876.5 kB 4.2 MB/s eta 0:00:00\n",
      "Using cached sentence_transformers-3.3.0-py3-none-any.whl (268 kB)\n",
      "Using cached dnspython-2.7.0-py3-none-any.whl (313 kB)\n",
      "Using cached huggingface_hub-0.26.2-py3-none-any.whl (447 kB)\n",
      "Using cached transformers-4.46.2-py3-none-any.whl (10.0 MB)\n",
      "Downloading safetensors-0.4.5-cp311-none-win_amd64.whl (285 kB)\n",
      "   ---------------------------------------- 0.0/286.0 kB ? eta -:--:--\n",
      "   ---------------------------------------- 286.0/286.0 kB 8.9 MB/s eta 0:00:00\n",
      "Downloading tokenizers-0.20.3-cp311-none-win_amd64.whl (2.4 MB)\n",
      "   ---------------------------------------- 0.0/2.4 MB ? eta -:--:--\n",
      "   -------- ------------------------------- 0.5/2.4 MB 10.0 MB/s eta 0:00:01\n",
      "   ------------- -------------------------- 0.8/2.4 MB 10.5 MB/s eta 0:00:01\n",
      "   ------------- -------------------------- 0.8/2.4 MB 10.5 MB/s eta 0:00:01\n",
      "   -------------- ------------------------- 0.9/2.4 MB 5.1 MB/s eta 0:00:01\n",
      "   ------------------------------- -------- 1.9/2.4 MB 10.0 MB/s eta 0:00:01\n",
      "   ----------------------------------- ---- 2.1/2.4 MB 8.4 MB/s eta 0:00:01\n",
      "   ---------------------------------------  2.4/2.4 MB 8.3 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 2.4/2.4 MB 8.0 MB/s eta 0:00:00\n",
      "Installing collected packages: safetensors, dnspython, pymongo, huggingface-hub, tokenizers, transformers, sentence-transformers\n",
      "Successfully installed dnspython-2.7.0 huggingface-hub-0.26.2 pymongo-4.10.1 safetensors-0.4.5 sentence-transformers-3.3.0 tokenizers-0.20.3 transformers-4.46.2\n"
     ]
    }
   ],
   "source": [
    "!pip install google-generativeai\n",
    "!pip install pymongo sentence-transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "m9MYHyhivUJh"
   },
   "outputs": [],
   "source": [
    "from pymongo import MongoClient\n",
    "from sentence_transformers import SentenceTransformer\n",
    "import re"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fQgH1hpt4Rox"
   },
   "source": [
    "# Σύνδεση με την Βάση"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "tOSQOJigvY-Q",
    "outputId": "6585ba60-fe69-49d0-abf1-c49b479f977d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Connected to MongoDB successfully.\n"
     ]
    }
   ],
   "source": [
    "mongo_uri = \"mongodb+srv://GiorgosZiakas:AdGiorgosMin24@cluster0.itaqk.mongodb.net/Weather\"\n",
    "mongo_client = MongoClient(mongo_uri)\n",
    "\n",
    "# Επιλογή βάσης δεδομένων και συλλογής\n",
    "db = mongo_client[\"Weather\"]\n",
    "weather_collection = db[\"Hackathon\"]\n",
    "\n",
    "print(\"Connected to MongoDB successfully.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6cIZaw_P4Ykd"
   },
   "source": [
    "# Φόρτωση του μοντέλου SentenceTransformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "UKEU8mwOveS4",
    "outputId": "63248809-df30-49be-a75b-a451ac65f74a"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9aaa5f22b92e4a2fa08a19cb9c828f8d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "modules.json:   0%|          | 0.00/385 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ziziz\\AppData\\Roaming\\Python\\Python311\\site-packages\\huggingface_hub\\file_download.py:139: UserWarning: `huggingface_hub` cache-system uses symlinks by default to efficiently store duplicated files but your machine does not support them in C:\\Users\\ziziz\\.cache\\huggingface\\hub\\models--thenlper--gte-large. Caching files will still work but in a degraded version that might require more space on your disk. This warning can be disabled by setting the `HF_HUB_DISABLE_SYMLINKS_WARNING` environment variable. For more details, see https://huggingface.co/docs/huggingface_hub/how-to-cache#limitations.\n",
      "To support symlinks on Windows, you either need to activate Developer Mode or to run Python as an administrator. In order to activate developer mode, see this article: https://docs.microsoft.com/en-us/windows/apps/get-started/enable-your-device-for-development\n",
      "  warnings.warn(message)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e0b41d2f0a504c05aa9b236fdfa10ce2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "README.md:   0%|          | 0.00/67.9k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "784ed39990664ba785f65837199c006b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "sentence_bert_config.json:   0%|          | 0.00/57.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "085dd8f84e0a4810b514be20ea7757fc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/619 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1ed7526543f8443187bac937f6c07374",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/670M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "80fe835b4e1a4faa84e948d414cef445",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/342 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "674c6a1c9bd44c3193fda6e3682daf7a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "68efe36fdaff4013a20cc2a8bceddc2c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/712k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f1478b227b064537b625f1c4d3a48a4f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/125 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0f37a1ca572a4332a0ec7456bd05c3c6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "1_Pooling/config.json:   0%|          | 0.00/191 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded SentenceTransformer model successfully.\n"
     ]
    }
   ],
   "source": [
    "# Φόρτωση του SentenceTransformer μοντέλου\n",
    "embedding_model = SentenceTransformer(\"thenlper/gte-large\")\n",
    "print(\"Loaded SentenceTransformer model successfully.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5T3JzJVH4iEL"
   },
   "source": [
    "# Embedding functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "xEJfnXuRvkoE"
   },
   "outputs": [],
   "source": [
    "# Συνάρτηση για τη δημιουργία embedding χρησιμοποιώντας το SentenceTransformer\n",
    "def get_embedding(text):\n",
    "    if not text.strip():\n",
    "        print(\"Attempted to get embedding for empty text.\")\n",
    "        return []\n",
    "\n",
    "    # Χρήση της μεθόδου encode για τη δημιουργία του embedding\n",
    "    embedding = embedding_model.encode(text)\n",
    "    return embedding.tolist()\n",
    "\n",
    "\n",
    "# Συνάρτηση για μετατροπή εγγραφής σε περιγραφικό κείμενο\n",
    "def create_text_from_record(record):\n",
    "    text = (f\"Location: {record.get('name', 'Unknown')}, Latitude: {record.get('latitude', 'N/A')}, \"\n",
    "            f\"Longitude: {record.get('longitude', 'N/A')}, Date: {record.get('date', 'N/A')}, \"\n",
    "            f\"Time: {record.get('time', 'N/A')}, Temperature: {record.get('temperature', 'N/A')}°C, \"\n",
    "            f\"Wind Speed: {record.get('wind_speed', 'N/A')} kph, Wind Direction: {record.get('wind_dir', 'N/A')}, \"\n",
    "            f\"Humidity: {record.get('humidity', 'N/A')}%, Visibility: {record.get('visibility', 'N/A')} km\")\n",
    "    return text\n",
    "\n",
    "\n",
    "# Δημιουργία και αποθήκευση embeddings για κάθε εγγραφή στη συλλογή\n",
    "def generate_and_store_embeddings():\n",
    "    documents = weather_collection.find()\n",
    "\n",
    "    for doc in documents:\n",
    "        # Δημιουργία περιγραφικού κειμένου από την εγγραφή\n",
    "        text = create_text_from_record(doc)\n",
    "\n",
    "        # Δημιουργία embedding για το κείμενο\n",
    "        embedding = get_embedding(text)\n",
    "\n",
    "        # Αποθήκευση του embedding στην εγγραφή\n",
    "        weather_collection.update_one(\n",
    "            {\"_id\": doc[\"_id\"]},\n",
    "            {\"$set\": {\"embedding\": embedding.tolist()}}\n",
    "        )\n",
    "        print(f\"Stored embedding for document with _id: {doc['_id']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OyHDKj1Z4v_T"
   },
   "source": [
    "# MongoDB call"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "l-T4gd7EvngF"
   },
   "outputs": [],
   "source": [
    "def extract_date_and_locations(query):\n",
    "    # Εξαγωγή ημερομηνίας με χρήση regex\n",
    "    date_match = re.search(r\"\\d{4}-\\d{2}-\\d{2}\", query)\n",
    "    date = date_match.group(0) if date_match else None\n",
    "\n",
    "    # Λίστα γνωστών τοποθεσιών (ενημέρωσέ την με τις δικές σου τοποθεσίες)\n",
    "    locations = [\"Anthousa\", \"Dioni\", \"OtherLocation\"]  # Προσάρμοσε αυτή τη λίστα\n",
    "    found_locations = []\n",
    "    for loc in locations:\n",
    "        if loc.lower() in query.lower():\n",
    "            found_locations.append(loc)\n",
    "\n",
    "    return date, found_locations\n",
    "\n",
    "def query_results(query):\n",
    "    \"\"\"\n",
    "    Δημιουργεί embedding για την ερώτηση και εκτελεί αναζήτηση στη MongoDB\n",
    "    για τις πιο σχετικές εγγραφές, χρησιμοποιώντας τον δείκτη `vector_index`\n",
    "    και φίλτρα για ημερομηνία και τοποθεσία.\n",
    "    \"\"\"\n",
    "    # Δημιουργία embedding της ερώτησης\n",
    "    query_embedding = get_embedding(query)\n",
    "\n",
    "    # Εξαγωγή ημερομηνίας και τοποθεσίας από την ερώτηση\n",
    "    date_filter, location_filters = extract_date_and_locations(query)\n",
    "\n",
    "    # Δημιουργία φίλτρου για την αναζήτηση\n",
    "    filter_conditions = {}\n",
    "    if date_filter:\n",
    "        filter_conditions['date'] = date_filter\n",
    "    if location_filters:\n",
    "        # Χρήση του τελεστή $in για να συμπεριληφθούν όλες οι τοποθεσίες\n",
    "        filter_conditions['name'] = {'$in': location_filters}\n",
    "\n",
    "    # Εκτέλεση αναζήτησης vector similarity με φίλτρα\n",
    "    pipeline = [\n",
    "        {\n",
    "\n",
    "            \"$vectorSearch\": {\n",
    "                \"index\": \"vector_index\",\n",
    "                \"path\": \"embedding\",\n",
    "                \"queryVector\": query_embedding,\n",
    "                \"numCandidates\": 150,\n",
    "                \"limit\": 5\n",
    "            }\n",
    "        }\n",
    "    ]\n",
    "\n",
    "    # Εάν υπάρχουν φίλτρα, τα προσθέτουμε στο pipeline\n",
    "    if filter_conditions:\n",
    "        pipeline[0][\"$vectorSearch\"][\"filter\"] = filter_conditions\n",
    "\n",
    "    results = db.Hackathon.aggregate(pipeline)\n",
    "    return list(results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VS9YMZFW5Fr0"
   },
   "source": [
    "# Configuration of the database response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "GuTTm1c3vqMh"
   },
   "outputs": [],
   "source": [
    "# Συνάρτηση για τη διαμόρφωση των αποτελεσμάτων της αναζήτησης σε κείμενο\n",
    "def get_search_results(query):\n",
    "    \"\"\"\n",
    "    Λαμβάνει τα πιο σχετικά αποτελέσματα από την MongoDB και δημιουργεί\n",
    "    μια περιγραφή για το LLM.\n",
    "    \"\"\"\n",
    "\n",
    "    results = query_results(query)\n",
    "\n",
    "    # Δημιουργία περιγραφικού κειμένου για τα αποτελέσματα\n",
    "    search_results = \"\"\n",
    "    for result in results:\n",
    "        search_results += create_text_from_record(result) + \"\\n\"\n",
    "    return search_results, results\n",
    "\n",
    "\n",
    "# Συνάρτηση για την ανάλυση των καιρικών συνθηκών και την παραγωγή οδηγιών\n",
    "def analyze_weather_conditions(results):\n",
    "    \"\"\"\n",
    "    Αναλύει τα αποτελέσματα και εντοπίζει επικίνδυνες συνθήκες.\n",
    "    Επιστρέφει μια λίστα με οδηγίες.\n",
    "    \"\"\"\n",
    "    instructions = []\n",
    "    for result in results:\n",
    "        temperature = result.get('temperature', 0)\n",
    "        humidity = result.get('humidity', 100)\n",
    "        wind_speed = result.get('wind_speed', 0)\n",
    "        wind_dir = result.get('wind_dir', 'N/A')\n",
    "        location = result.get('name', 'Unknown')\n",
    "        date = result.get('date', 'N/A')\n",
    "        time = result.get('time', 'N/A')\n",
    "\n",
    "        # Εντοπισμός επικίνδυνων συνθηκών\n",
    "        if temperature > 30 and humidity < 20:\n",
    "            instruction = f\"High risk of fire in {location} on {date} at {time}. \"\n",
    "            if wind_dir in ['NE', 'ENE', 'NNE']:\n",
    "                instruction += f\"Recommend sending drone to the northeast direction due to {wind_dir} winds.\"\n",
    "            elif wind_dir in ['E', 'SE', 'SSE']:\n",
    "                instruction += f\"Recommend sending drone to the southeast direction due to {wind_dir} winds.\"\n",
    "            # Προσθέστε επιπλέον συνθήκες για άλλες κατευθύνσεις ανέμου\n",
    "            else:\n",
    "                instruction += f\"Recommend monitoring the area closely.\"\n",
    "            instructions.append(instruction)\n",
    "    return instructions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xOTbfOIg5RpL"
   },
   "source": [
    "# GenAi key configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "mJty6Lwzvw15"
   },
   "outputs": [],
   "source": [
    "# google colab's way to set the api key\n",
    "import google.generativeai as palm\n",
    "from google.colab import userdata\n",
    "\n",
    "# Set your Gemini API key\n",
    "GOOGLE_API_KEY = userdata.get('GOOGLE_API_KEY') # έτσι δουλεύει στο colab, τοπικά θα είναι διαφορετικό\n",
    "palm.configure(api_key=GOOGLE_API_KEY)\n",
    "\n",
    "model = palm.GenerativeModel('gemini-1.5-flash')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# local way to set the api key\n",
    "import google.generativeai as palm\n",
    "import os\n",
    "\n",
    "# Set your Gemini API key\n",
    "os.environ['GOOGLE_API_KEY']='AIzaSyCdF0puCdMW-s-9WmCNdSY4eLanHO9yJWQ'\n",
    "palm.configure(api_key=os.getenv(\"GOOGLE_API_KEY\"))\n",
    "\n",
    "model = palm.GenerativeModel('gemini-1.5-flash')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "OVht9rd8wgkL"
   },
   "outputs": [],
   "source": [
    "import textwrap\n",
    "\n",
    "from IPython.display import display\n",
    "from IPython.display import Markdown\n",
    "\n",
    "def to_markdown(text):\n",
    "  text = text.replace('•', '  *')\n",
    "  return Markdown(textwrap.indent(text, '> ', predicate=lambda _: True))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 54
    },
    "id": "51QZsRrnwVMW",
    "outputId": "c7950366-b75c-4689-b40b-608cf5ca99ce"
   },
   "outputs": [],
   "source": [
    "# test question\n",
    "## %%time\n",
    "response = model.generate_content(\"What is the meaning of life?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 579
    },
    "id": "SnWRkfZCwsVX",
    "outputId": "d7760f19-bdb4-4b39-9e26-d5f066f4c762"
   },
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "> There's no single, universally accepted answer to the meaning of life.  It's a question that has been pondered by philosophers, theologians, and individuals for centuries.  The meaning is often considered to be subjective and personal, shaped by individual beliefs, experiences, and values.\n",
       "> \n",
       "> Some common perspectives include:\n",
       "> \n",
       "> * **Nihilism:**  The belief that life is inherently without meaning or purpose.\n",
       "> * **Existentialism:** The belief that individuals create their own meaning and purpose through their choices and actions.\n",
       "> * **Absurdism:** The belief that the search for meaning in a meaningless universe is inherently absurd, but that we should embrace this absurdity.\n",
       "> * **Spiritual and Religious Beliefs:** Many religions offer answers about the meaning of life, often involving serving a higher power, achieving enlightenment, or following a divine plan.\n",
       "> * **Hedonism:** The pursuit of pleasure and avoidance of pain as the primary goal in life.\n",
       "> * **Humanism:** Focusing on human values, reason, and ethics, emphasizing the importance of human flourishing and social justice.\n",
       "> \n",
       "> Ultimately, the meaning of life is what you make it.  It's a question of personal discovery and reflection, and the answer may evolve throughout your lifetime.  Instead of searching for a definitive answer, many find fulfillment by focusing on:\n",
       "> \n",
       "> * **Relationships:** Connecting with loved ones and building meaningful connections.\n",
       "> * **Contribution:** Making a positive impact on the world, however small.\n",
       "> * **Growth:** Continuously learning, developing, and challenging yourself.\n",
       "> * **Experiences:**  Exploring the world and engaging in activities that bring joy and fulfillment.\n",
       "> \n",
       "> The search for meaning itself can be a significant part of life's journey.\n"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "to_markdown(response.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vF1Lc40w53hA"
   },
   "source": [
    "# Where the magic happens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "id": "CV9kQDRisP18"
   },
   "outputs": [],
   "source": [
    "def generate_answer(query):\n",
    "    \"\"\"\n",
    "    Συνδυάζει την ερώτηση του χρήστη με τα αποτελέσματα της αναζήτησης,\n",
    "    αναλύει τις συνθήκες και χρησιμοποιεί το Gemini API για να παράγει την τελική απάντηση.\n",
    "    \"\"\"\n",
    "\n",
    "    # Λήψη των αποτελεσμάτων της αναζήτησης και των ακατέργαστων δεδομένων\n",
    "    source_information, results = get_search_results(query)\n",
    "\n",
    "    # Ανάλυση των συνθηκών για παραγωγή οδηγιών\n",
    "    instructions = analyze_weather_conditions(results)\n",
    "\n",
    "    # Δημιουργία του περιεχομένου για το LLM\n",
    "    if source_information.strip():\n",
    "        combined_information = (\n",
    "            f\"Question: {query}\\n\"\n",
    "            f\"\"\"When you detect conditions that indicate a high risk of fire,\n",
    "            you should provide specific fire prevention instructions, such as recommending drone surveillance in the direction of the wind.\n",
    "            If the conditions do not indicate a risk of fire, you should mention it.\"\"\"\n",
    "            f\"Using the following information, answer the question and provide any necessary fire prevention instructions:\\n\"\n",
    "            f\"{source_information}\\n\"\n",
    "            f\"If the query is irrelevant to the given information, say: 'That was irrelevant my friend'.\"\n",
    "        )\n",
    "\n",
    "    ### TEST TEXTS ###\n",
    "    # (e.g., temperature above 30°C, humidity below 20%, or specific wind directions)\n",
    "    # and provide any necessary fire prevention instructions:\n",
    "\n",
    "\n",
    "        if instructions:\n",
    "          combined_information += \"\\nDetected conditions:\\n\"\n",
    "          for instr in instructions:\n",
    "                combined_information += f\"- {instr}\\n\"\n",
    "    else:\n",
    "        combined_information = f\"Question: {query}\\nI couldn't find specific data matching your query.\"\n",
    "\n",
    "    prompt = (\"\"\"You are a helpful assistant that provides precise weather information, using text from the reference passage included below.\n",
    "\n",
    "    QUESTION: '{query}'\n",
    "    PASSAGE: '{relevant_passage}'\n",
    "    ANSWER:\n",
    "    \"\"\").format(query=query, relevant_passage=combined_information)\n",
    "\n",
    "    response = model.generate_content(prompt)\n",
    "    answer = response.text\n",
    "    print(\"instructions: \", instructions)\n",
    "    print(\"combined_information: \", combined_information)\n",
    "    return answer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "id": "2vGAwaweAngc"
   },
   "outputs": [],
   "source": [
    "# alternative function (for testing)\n",
    "def generate_answer2(query):\n",
    "    \"\"\"\n",
    "    Συνδυάζει την ερώτηση του χρήστη με τα αποτελέσματα της αναζήτησης,\n",
    "    αναλύει τις συνθήκες και χρησιμοποιεί το Gemini API για να παράγει την τελική απάντηση.\n",
    "    \"\"\"\n",
    "\n",
    "    # Λήψη των αποτελεσμάτων της αναζήτησης και των ακατέργαστων δεδομένων\n",
    "    source_information, results = get_search_results(query)\n",
    "\n",
    "    # Ανάλυση των συνθηκών για παραγωγή οδηγιών\n",
    "    instructions = analyze_weather_conditions(results)\n",
    "\n",
    "    # Δημιουργία του περιεχομένου για το LLM\n",
    "    if source_information.strip():\n",
    "        combined_information = (\n",
    "          f\"{source_information}\"\n",
    "        )\n",
    "        # combined_information = (\n",
    "        #     f\"Question: {query}\\n\"\n",
    "        #     f\"\"\"When you detect conditions that indicate a high risk of fire,\n",
    "        #     you should provide specific fire prevention instructions, such as recommending drone surveillance in the direction of the wind.\n",
    "        #     If the conditions do not indicate a risk of fire, you should mention it.\"\"\"\n",
    "        #     f\"Using the following information, answer the question and provide any necessary fire prevention instructions:\\n\"\n",
    "        #     f\"{source_information}\\n\"\n",
    "        #     f\"If the query is irrelevant to the given information, say: 'That was irrelevant my friend'.\"\n",
    "        # )\n",
    "\n",
    "    ### TEST TEXTS ###\n",
    "    # (e.g., temperature above 30°C, humidity below 20%, or specific wind directions)\n",
    "    # and provide any necessary fire prevention instructions:\n",
    "\n",
    "\n",
    "        if instructions:\n",
    "          combined_information += \"\\nDetected conditions:\\n\"\n",
    "          for instr in instructions:\n",
    "                combined_information += f\"- {instr}\\n\"\n",
    "    else:\n",
    "        combined_information = f\"Question: {query}\\nI couldn't find specific data matching your query.\"\n",
    "\n",
    "    prompt = (\n",
    "        f\"You are a helpful assistant that provides precise weather information, using text from the reference passage included below.\"\n",
    "        f\"Respond in a complete sentence and make sure that your response is easy to understand for everyone.\"\n",
    "        f\"When you detect conditions that indicate a high risk of fire, you should provide specific fire prevention instructions, such as recommending drone surveillance in the direction of the wind.\"\n",
    "        f\"If the conditions do not indicate a risk of fire, mention it.\"\n",
    "        f\"If the query is irrelevant to the given information, say: 'That was irrelevant my friend'.\"\n",
    "        f\"Provide the answer in a user friendly markdown format.\"\n",
    "        f\"QUESTION: '{query}'\"\n",
    "        f\"PASSAGE: '{combined_information}\"\n",
    "        f\"ANSWER: \"\n",
    "        )\n",
    "\n",
    "    response = model.generate_content(prompt)\n",
    "    answer = response.text\n",
    "    print(\"instructions: \", instructions)\n",
    "    print(\"combined_information: \", combined_information)\n",
    "    return answer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZTE01JBk6BDW"
   },
   "source": [
    "# Test queries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 146
    },
    "id": "dJyuhXlLti8p",
    "outputId": "af93ded1-86c2-48b6-b7c1-addb880da470"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "instructions:  ['High risk of fire in Anthousa on 2021-08-05 at 1200. Recommend sending drone to the northeast direction due to ENE winds.']\n",
      "combined_information:  Location: Anthousa, Latitude: 38.025, Longitude: 23.876, Date: 2021-08-05, Time: 900, Temperature: 37°C, Wind Speed: 8 kph, Wind Direction: NNE, Humidity: 20%, Visibility: 10 km\n",
      "Location: Anthousa, Latitude: 38.025, Longitude: 23.876, Date: 2021-08-05, Time: 600, Temperature: 28°C, Wind Speed: 8 kph, Wind Direction: N, Humidity: 26%, Visibility: 10 km\n",
      "Location: Anthousa, Latitude: 38.025, Longitude: 23.876, Date: 2021-08-05, Time: 1800, Temperature: 39°C, Wind Speed: 9 kph, Wind Direction: S, Humidity: 23%, Visibility: 10 km\n",
      "Location: Anthousa, Latitude: 38.025, Longitude: 23.876, Date: 2021-08-05, Time: 2100, Temperature: 34°C, Wind Speed: 3 kph, Wind Direction: WSW, Humidity: 31%, Visibility: 10 km\n",
      "Location: Anthousa, Latitude: 38.025, Longitude: 23.876, Date: 2021-08-05, Time: 1200, Temperature: 38°C, Wind Speed: 8 kph, Wind Direction: ENE, Humidity: 19%, Visibility: 10 km\n",
      "\n",
      "Detected conditions:\n",
      "- High risk of fire in Anthousa on 2021-08-05 at 1200. Recommend sending drone to the northeast direction due to ENE winds.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "query = \"What locations are covered in the dataset?\"\n",
    "query1 = \"On 2019-05-01 in which region had we the highest temperature: 'Dioni' or 'Anthousa'?\"\n",
    "query2 = \"Which locations have high wind levels on 2022-08-05?\"\n",
    "query3 = \"What is my age?\"\n",
    "query4 = \"What conditions do you think pose a risk of fire?\" # ενδιαφέρουσα απάντηση\n",
    "query5 = \"What are the weather conditions in Dioni on 2019-05-01?\"\n",
    "query6 = \"What are the fire prevention recommendations for Anthousa on 2021-08-05?\" # Εδώ βρίσκει instructions, και μετά δίνει σαν απάντηση μόνο αυτά\n",
    "query7 = \"What was the hottest time on 2021-08-05 in Anthousa?\"\n",
    "\n",
    "answer = generate_answer2(query7)\n",
    "#print(answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 80
    },
    "id": "YfSZyz5Gtrfs",
    "outputId": "52c0d04f-ff82-43d0-cfa0-443525f3e93e"
   },
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "> The hottest time in Anthousa on August 5th, 2021, was at 6 PM, with a temperature of 39°C.  There is a high risk of fire at 12 PM with an ENE wind, so drone surveillance in that direction is recommended.\n"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#print(answer)\n",
    "to_markdown(answer)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
